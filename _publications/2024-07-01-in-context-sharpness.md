---
title: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
collection: publications
category: conferences
permalink: /publication/2024-07-01-in-context-sharpness
excerpt: 'We propose using in-context sharpness as an alert signal for hallucination mitigation in language models.'
date: 2024-07-01
venue: 'ICML 2024'
paperurl: 'https://proceedings.mlr.press/'
slidesurl: ''
bibtexurl: ''
citation: 'Shiqi Chen, Miao Xiong, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, Junxian He. (2024). &quot;In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation.&quot; <i>Proceedings of the 41st International Conference on Machine Learning (ICML)</i>.'
---
This paper introduces the concept of in-context sharpness as an inner representation signal to detect and mitigate hallucinations in language models.