---
title: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
collection: publications
category: conferences
permalink: /publication/2024-07-01-in-context-sharpness
excerpt: 'We propose using in-context sharpness as alerts for hallucination mitigation in LLMs.'
date: 2024-07-01
venue: 'ICML 2024'
paperurl: ''
slidesurl: ''
bibtexurl: ''
citation: 'Shiqi Chen, Miao Xiong, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, Junxian He. (2024). \'In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation.\' <i>International Conference on Machine Learning (ICML)</i>.'
---
This paper introduces a novel approach to detect and mitigate hallucinations in large language models using in-context sharpness metrics.